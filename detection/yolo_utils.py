import os
import yaml
from ultralytics import YOLO
from django.conf import settings
from django.core.files import File
from .models import Annotation, DetectionResult
from PIL import Image
import shutil
import random


class YOLOTrainer:
    def __init__(self, ml_model):
        self.ml_model = ml_model
        self.dataset = ml_model.dataset
        self.model = None


    def debug_annotations(self):
        """–ì–ª—É–±–æ–∫–∞—è –æ—Ç–ª–∞–¥–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å —É—á–µ—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"""
        print("=== –ì–õ–£–ë–û–ö–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ê–ù–ù–û–¢–ê–¶–ò–ô ===")

        all_annotations = Annotation.objects.filter(image__dataset=self.dataset)
        print(f"–í—Å–µ–≥–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ –ë–î: {all_annotations.count()}")

        if all_annotations.count() == 0:
            print("‚ùå –ù–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö!")
            return False

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
        valid_annotations = 0
        invalid_annotations = []

        for i, ann in enumerate(all_annotations):
            print(f"\n--- –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è {i + 1} ---")
            print(f"  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {ann.image.original_filename}")
            print(f"  –ú–µ—Ç–∫–∞: {ann.label}")
            print(f"  –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ): x={ann.x}, y={ann.y}, width={ann.width}, height={ann.height}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if not os.path.exists(ann.image.image.path):
                print("  ‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
                invalid_annotations.append(ann)
                continue

            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            try:
                with Image.open(ann.image.image.path) as img:
                    img_width, img_height = img.size
                print(f"  –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_width}x{img_height}")

                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –≤ –ø–∏–∫—Å–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                x_min_px = ann.x * img_width
                y_min_px = ann.y * img_height
                x_max_px = (ann.x + ann.width) * img_width
                y_max_px = (ann.y + ann.height) * img_height

                print(f"  BBOX –≤ –ø–∏–∫—Å–µ–ª—è—Ö: ({x_min_px:.1f}, {y_min_px:.1f}) -> ({x_max_px:.1f}, {y_max_px:.1f})")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –≤ –ø–∏–∫—Å–µ–ª—è—Ö
                if (x_min_px < 0 or y_min_px < 0 or
                        x_max_px > img_width or y_max_px > img_height):
                    print(f"  ‚ùå BBOX –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!")
                    invalid_annotations.append(ann)
                    continue

                if ann.width <= 0 or ann.height <= 0:
                    print(f"  ‚ùå –ù—É–ª–µ–≤—ã–µ –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã BBOX!")
                    invalid_annotations.append(ann)
                    continue

                # –ö–ª—é—á–µ–≤–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –£–ñ–ï –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã!
                # YOLO —Ñ–æ—Ä–º–∞—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–∞
                x_center = ann.x + ann.width / 2.0
                y_center = ann.y + ann.height / 2.0
                width_norm = ann.width
                height_norm = ann.height

                print(
                    f"  YOLO —Ñ–æ—Ä–º–∞—Ç (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π): class_id, {x_center:.6f}, {y_center:.6f}, {width_norm:.6f}, {height_norm:.6f}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å YOLO –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                if (0 <= x_center <= 1 and 0 <= y_center <= 1 and
                        0 < width_norm <= 1 and 0 < height_norm <= 1):
                    valid_annotations += 1
                    print("  ‚úÖ –í–∞–ª–∏–¥–Ω–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è")
                else:
                    print(f"  ‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ YOLO –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã!")
                    invalid_annotations.append(ann)

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
                invalid_annotations.append(ann)

        print(f"\n=== –ò–¢–û–ì–ò –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò ===")
        print(f"–í–∞–ª–∏–¥–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {valid_annotations}")
        print(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {len(invalid_annotations)}")

        if valid_annotations == 0:
            print("‚ùå –ù–ï–¢ –í–ê–õ–ò–î–ù–´–• –ê–ù–ù–û–¢–ê–¶–ò–ô –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø!")
            return False

        return True

    def prepare_yolo_dataset(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO —Å —É—á–µ—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"""
        try:
            dataset_dir = os.path.join(settings.MEDIA_ROOT, 'yolo_datasets', f'dataset_{self.dataset.id}')
            print(f"–°–æ–∑–¥–∞–µ–º dataset –≤: {dataset_dir}")

            # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            if os.path.exists(dataset_dir):
                print("–û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –≤–µ—Ä—Å–∏—é dataset")
                shutil.rmtree(dataset_dir)

            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
            train_images_dir = os.path.join(dataset_dir, 'images', 'train')
            train_labels_dir = os.path.join(dataset_dir, 'labels', 'train')
            val_images_dir = os.path.join(dataset_dir, 'images', 'val')
            val_labels_dir = os.path.join(dataset_dir, 'labels', 'val')

            for dir_path in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir]:
                os.makedirs(dir_path, exist_ok=True)
                print(f"–°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {dir_path}")

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
            images_with_annotations = []
            classes = set()

            print("–°–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏...")
            for image in self.dataset.imagefile_set.all():
                annotations = Annotation.objects.filter(image=image)
                if annotations.exists():
                    images_with_annotations.append((image, annotations))
                    for ann in annotations:
                        classes.add(ann.label)
                    print(f"  {image.original_filename}: {annotations.count()} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")

            if not images_with_annotations:
                raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏")

            print(f"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π: {len(images_with_annotations)}")
            print(f"–ö–ª–∞—Å—Å—ã: {sorted(classes)}")

            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val
            random.shuffle(images_with_annotations)
            split_idx = int(0.8 * len(images_with_annotations))
            train_images = images_with_annotations[:split_idx]
            val_images = images_with_annotations[split_idx:]

            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º—É–º 1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            if not val_images and train_images:
                val_images = [train_images.pop()]

            print(f"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {len(train_images)} train, {len(val_images)} val")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            train_stats = self._process_split_corrected(train_images, train_images_dir, train_labels_dir, classes,
                                                        "train")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            val_stats = self._process_split_corrected(val_images, val_images_dir, val_labels_dir, classes, "val")

            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            if train_stats['images'] == 0:
                raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

            # –°–æ–∑–¥–∞–µ–º dataset.yaml –¥–ª—è YOLO
            dataset_yaml = {
                'path': str(dataset_dir),
                'train': 'images/train',
                'val': 'images/val',
                'nc': len(classes),
                'names': {i: name for i, name in enumerate(sorted(classes))}
            }

            yaml_path = os.path.join(dataset_dir, 'dataset.yaml')
            with open(yaml_path, 'w', encoding='utf-8') as f:
                yaml.dump(dataset_yaml, f, default_flow_style=False, sort_keys=False, allow_unicode=True)

            print("=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–ê–ù–ù–´–• ===")
            print(f"–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {train_stats['images']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {train_stats['annotations']} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
            print(f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {val_stats['images']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {val_stats['annotations']} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
            print(f"–í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤: {len(classes)}")
            print(f"YAML —Ñ–∞–π–ª: {yaml_path}")

            return yaml_path, len(classes), len(images_with_annotations)

        except Exception as e:
            if 'dataset_dir' in locals() and os.path.exists(dataset_dir):
                shutil.rmtree(dataset_dir, ignore_errors=True)
            raise Exception(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö YOLO: {str(e)}")

    def _process_split_corrected(self, images_data, images_dir, labels_dir, classes, split_name):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —É—á–µ—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"""
        total_annotations = 0
        processed_images = 0

        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {split_name} –¥–∞–Ω–Ω—ã—Ö (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã)...")

        for image, annotations in images_data:
            try:
                img_path = image.image.path
                if not os.path.exists(img_path):
                    print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img_path}")
                    continue

                img_filename = os.path.basename(img_path)
                dest_img_path = os.path.join(images_dir, img_filename)

                # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                if not os.path.exists(dest_img_path):
                    shutil.copy2(img_path, dest_img_path)

                # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Ä–∞–∑–º–µ—Ç–∫–∏
                label_filename = os.path.splitext(img_filename)[0] + '.txt'
                label_path = os.path.join(labels_dir, label_filename)

                annotation_count = 0
                with open(label_path, 'w') as f:
                    for ann in annotations:
                        try:
                            x_center = ann.x + ann.width / 2.0
                            y_center = ann.y + ann.height / 2.0
                            width_norm = ann.width
                            height_norm = ann.height

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                            if (0 <= x_center <= 1 and 0 <= y_center <= 1 and
                                    0 < width_norm <= 1 and 0 < height_norm <= 1 and
                                    width_norm > 0.01 and height_norm > 0.01):  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä 1%

                                class_idx = sorted(classes).index(ann.label)
                                f.write(
                                    f"{class_idx} {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\n")
                                annotation_count += 1
                                print(
                                    f"  ‚úÖ –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: {x_center:.3f}, {y_center:.3f}, {width_norm:.3f}, {height_norm:.3f}")
                            else:
                                print(f"  ‚ùå –ü—Ä–æ–ø—É—â–µ–Ω–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –≤ {img_filename}: –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã")
                                print(
                                    f"     x_center={x_center:.3f}, y_center={y_center:.3f}, width={width_norm:.3f}, height={height_norm:.3f}")

                        except Exception as e:
                            print(f"  ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {e}")
                            continue

                if annotation_count > 0:
                    processed_images += 1
                    total_annotations += annotation_count
                    print(f"  ‚úÖ {img_filename}: {annotation_count} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
                else:
                    # –£–¥–∞–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
                    if os.path.exists(dest_img_path):
                        os.remove(dest_img_path)
                    if os.path.exists(label_path):
                        os.remove(label_path)
                    print(f"  ‚ùå –£–¥–∞–ª–µ–Ω–æ: {img_filename} (–Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π)")

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image.original_filename}: {e}")
                continue

        print(f"{split_name}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {total_annotations} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
        return {'images': processed_images, 'annotations': total_annotations}

    def _get_training_config(self, num_images, num_classes):
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–æ–≤

        –ü–ê–ú–Ø–¢–ö–ê –ü–û –ü–ê–†–ê–ú–ï–¢–†–ê–ú –û–ë–£–ß–ï–ù–ò–Ø:

        –ú–ê–õ–ï–ù–¨–ö–ò–ô –î–ê–¢–ê–°–ï–¢ (< 100 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π):
          - epochs: 50-100 (–±–æ–ª—å—à–µ —ç–ø–æ—Ö –¥–ª—è –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ –º–∞–ª–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö)
          - imgsz: 640 (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞)
          - batch: 4-8 (–º–µ–Ω—å—à–µ –±–∞—Ç—á–∏ –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö)
          - lr0: 0.01 (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è)
          - augment: True (–∞–∫—Ç–∏–≤–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è)
          - patience: 20 (–±–æ–ª—å—à–µ —Ç–µ—Ä–ø–µ–Ω–∏—è –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤)

        –°–†–ï–î–ù–ò–ô –î–ê–¢–ê–°–ï–¢ (100-500 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π):
          - epochs: 100-150
          - imgsz: 640
          - batch: 8-16
          - lr0: 0.01
          - augment: True
          - patience: 30

        –ë–û–õ–¨–®–û–ô –î–ê–¢–ê–°–ï–¢ (> 500 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π):
          - epochs: 150-300
          - imgsz: 640
          - batch: 16-32
          - lr0: 0.01
          - augment: True (–º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é)
          - patience: 50

        –ú–ê–õ–û –ö–õ–ê–°–°–û–í (1-3 –∫–ª–∞—Å—Å–∞):
          - epochs: –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å –Ω–∞ 20%
          - lr0: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è

        –ú–ù–û–ì–û –ö–õ–ê–°–°–û–í (> 10 –∫–ª–∞—Å—Å–æ–≤):
          - epochs: —É–≤–µ–ª–∏—á–∏—Ç—å –Ω–∞ 30-50%
          - lr0: –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å –¥–æ 0.005 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
          - augment: –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ True
        """

        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        config = {
            'epochs': 100,
            'imgsz': 640,
            'batch': 16,
            'lr0': 0.01,
            'augment': True,
            'patience': 30,
            'optimizer': 'auto',
            'weight_decay': 0.0005,
            'momentum': 0.937,
            'warmup_epochs': 3,
            'warmup_momentum': 0.8,
            'box': 7.5,  # weight for box loss
            'cls': 0.5,  # weight for class loss
            'dfl': 1.5,  # weight for dfl loss
        }

        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö
        if num_images < 100:
            # –ú–∞–ª—ã–π –¥–∞—Ç–∞—Å–µ—Ç
            config.update({
                'epochs': 80,
                'batch': max(4, min(8, num_images // 10)),  # –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π batch
                'patience': 20,
                'augment': True,  # –≤–∞–∂–Ω–∞ –∞–∫—Ç–∏–≤–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
                'lr0': 0.01,
                'close_mosaic': 10,  # —Ä–∞–Ω–Ω–µ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ mosaic –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            })
        elif num_images < 500:
            # –°—Ä–µ–¥–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç
            config.update({
                'epochs': 120,
                'batch': max(8, min(16, num_images // 30)),
                'patience': 30,
                'augment': True,
            })
        else:
            # –ë–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç
            config.update({
                'epochs': 150,
                'batch': max(16, min(32, num_images // 50)),
                'patience': 50,
                'augment': True,
            })

        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
        if num_classes <= 3:
            # –ú–∞–ª–æ –∫–ª–∞—Å—Å–æ–≤ - –º–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å –±—ã—Å—Ç—Ä–µ–µ
            config['epochs'] = max(50, int(config['epochs'] * 0.8))
        elif num_classes > 10:
            # –ú–Ω–æ–≥–æ –∫–ª–∞—Å—Å–æ–≤ - –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏
            config['epochs'] = int(config['epochs'] * 1.3)
            config['lr0'] = 0.005  # –±–æ–ª–µ–µ –Ω–∏–∑–∫–∞—è LR –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            config['patience'] = int(config['patience'] * 1.2)

        print(f"‚öôÔ∏è  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è {num_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {num_classes} –∫–ª–∞—Å—Å–æ–≤:")
        print(f"   Epochs: {config['epochs']}")
        print(f"   Batch: {config['batch']}")
        print(f"   Image size: {config['imgsz']}")
        print(f"   Learning rate: {config['lr0']}")
        print(f"   Patience: {config['patience']}")

        return config

    def train_model(self):
        """–û–±—É—á–µ–Ω–∏–µ YOLO –º–æ–¥–µ–ª–∏ –±–µ–∑ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        try:
            print("=== –ù–ê–ß–ê–õ–û –ü–û–î–ì–û–¢–û–í–ö–ò –î–ê–ù–ù–´–• ===")

            # –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º –≥–ª—É–±–æ–∫—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
            if not self.debug_annotations():
                raise ValueError("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏")

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
            yaml_path, num_classes, num_images = self.prepare_yolo_dataset()

            if num_images == 0:
                raise ValueError("–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

            print(f"=== –ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø ===")
            print(f"–ö–ª–∞—Å—Å—ã: {num_classes}")
            print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {num_images}")
            print(f"YAML: {yaml_path}")

            if not os.path.exists(yaml_path):
                raise FileNotFoundError(f"YAML —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {yaml_path}")

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è
            training_config = self._get_training_config(num_images, num_classes)

            print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å YOLO...")
            self.model = YOLO('yolov8n.pt')

            # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
            training_params = {
                'data': yaml_path,
                'epochs': training_config['epochs'],
                'batch': training_config['batch'],
                'imgsz': training_config['imgsz'],
                'patience': training_config['patience'],
                'save': True,
                'exist_ok': True,
                'pretrained': True,
                'verbose': True,
                'project': os.path.join(settings.MEDIA_ROOT, 'yolo_training'),
                'name': f'model_{self.ml_model.id}',
                'lr0': training_config['lr0'],
                'optimizer': training_config['optimizer'],
                'weight_decay': training_config['weight_decay'],
                'momentum': training_config['momentum'],
                'warmup_epochs': training_config['warmup_epochs'],
                'warmup_momentum': training_config['warmup_momentum'],
                'box': training_config['box'],
                'cls': training_config['cls'],
                'dfl': training_config['dfl'],
                'augment': training_config['augment'],
            }

            if 'close_mosaic' in training_config:
                training_params['close_mosaic'] = training_config['close_mosaic']

            print("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")

            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
            results = self.model.train(**training_params)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            best_model_path = os.path.join(
                settings.MEDIA_ROOT, 'yolo_training', f'model_{self.ml_model.id}', 'weights', 'best.pt'
            )

            if os.path.exists(best_model_path):
                print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {best_model_path}")
                with open(best_model_path, 'rb') as f:
                    self.ml_model.model_file.save(f'model_{self.ml_model.id}.pt', File(f))

                print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                if hasattr(results, 'results_dict') and results.results_dict:
                    training_results = results.results_dict
                    self.ml_model.accuracy = training_results.get('metrics/mAP50(B)', 0)
                    self.ml_model.precision = training_results.get('metrics/precision(B)', 0)
                    self.ml_model.recall = training_results.get('metrics/recall(B)', 0)
                    self.ml_model.f1_score = training_results.get('metrics/f1(B)', 0)

                    print(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
                    print(f"  mAP50: {self.ml_model.accuracy:.3f}")
                    print(f"  Precision: {self.ml_model.precision:.3f}")
                    print(f"  Recall: {self.ml_model.recall:.3f}")
                    print(f"  F1: {self.ml_model.f1_score:.3f}")
                else:
                    self.ml_model.accuracy = 0.5
                    self.ml_model.precision = 0.5
                    self.ml_model.recall = 0.5
                    self.ml_model.f1_score = 0.5

                self.ml_model.save()

            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            temp_dataset_dir = os.path.join(settings.MEDIA_ROOT, 'yolo_datasets', f'dataset_{self.dataset.id}')
            if os.path.exists(temp_dataset_dir):
                print(f"–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {temp_dataset_dir}")
                shutil.rmtree(temp_dataset_dir, ignore_errors=True)

            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {str(e)}")
            import traceback
            traceback.print_exc()
            self.ml_model.training_log = f"–û—à–∏–±–∫–∞: {str(e)}"
            self.ml_model.save()
            return False


class YOLODetector:
    def __init__(self, ml_model):
        self.ml_model = ml_model
        self.model = None
        self.load_model()

    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            if self.ml_model.model_file and os.path.exists(self.ml_model.model_file.path):
                self.model = YOLO(self.ml_model.model_file.path)
                print("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                print(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª–∞—Å—Å—ã: {self.model.names}")
            else:
                raise ValueError("–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def detect_image(self, image_file, confidence=0.25):
        """–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
        if not self.model:
            self.load_model()

        image_path = image_file.image.path

        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é
            results = self.model.predict(
                source=image_path,
                conf=confidence,
                save=False,
                verbose=False
            )

            detections = []
            for result in results:
                boxes = result.boxes
                if boxes is not None and len(boxes) > 0:
                    for box in boxes:
                        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bounding box
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = box.conf[0].cpu().numpy()
                        class_id = int(box.cls[0].cpu().numpy())

                        # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –∫–ª–∞—Å—Å–∞
                        class_name = self.model.names.get(class_id, f'class_{class_id}')

                        detections.append({
                            'label': class_name,
                            'confidence': float(confidence),
                            'x': float(x1),
                            'y': float(y1),
                            'width': float(x2 - x1),
                            'height': float(y2 - y1),
                            'class_id': class_id
                        })

            return detections

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")
            return []

    def detect_dataset(self, confidence=0.25):
        """–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –≤–æ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ"""
        detection_count = 0

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏
        DetectionResult.objects.filter(ml_model=self.ml_model).delete()

        for image in self.ml_model.dataset.imagefile_set.all():
            detections = self.detect_image(image, confidence)

            for detection in detections:
                DetectionResult.objects.create(
                    dataset=self.ml_model.dataset,
                    image=image,
                    ml_model=self.ml_model,
                    detected_label=detection['label'],
                    confidence=detection['confidence'],
                    x=detection['x'],
                    y=detection['y'],
                    width=detection['width'],
                    height=detection['height']
                )
                detection_count += 1

        return detection_count